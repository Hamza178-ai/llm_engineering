{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b819a13d-d07b-4143-b8bb-41a0a9645af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485f7ea7-78c1-4d19-8fc4-c9c5b7f098b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "# creating an instance\n",
    "openai = OpenAI()\n",
    "system_prompt = \"You are a technical knowledge is at PhD level. \\\n",
    "A technician will ask you questions to explain some technical terms. \\\n",
    "Give a detailed answer \\\n",
    "and respond in Markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29480428-d365-4c71-b12a-f5f3651eee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(question):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "106c1e87-51e8-45cf-88b6-a7c9a0afc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "def ask_from_phd_MODEL_GPT ():\n",
    "    question = input(\"Ask from a PhD level Super Technician:  \")\n",
    "    if question is not None:\n",
    "        response = openai.chat.completions.create(\n",
    "            model = MODEL_GPT,\n",
    "            messages = messages_for(question)\n",
    "        )\n",
    "        display(Markdown(response.choices[0].message.content))\n",
    "    else:\n",
    "        print(\"Bye\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "def ask_from_phd_ollama():\n",
    "    question = input(\"Ask from a PhD level Super Technician:  \")\n",
    "    if question is not None:\n",
    "        response = ollama.chat(model=MODEL_LLAMA, messages=messages_for(question))\n",
    "        display(Markdown(response['message']['content']))\n",
    "    else:\n",
    "        print(\"Bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282cf6a-3dae-4396-b3ed-c8867c31894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_from_phd_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9fbb92-a045-4a02-80ce-d976e5159b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask from a PhD level Super Technician:   what is induction Bais and how it helps in model selections?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Induction Bias\n",
       "\n",
       "**Induction bias** refers to the assumptions made by a learning algorithm when it generalizes from a limited amount of training data to draw conclusions about unseen data. In the context of machine learning, it influences how the model interprets and learns the underlying patterns from the training data.\n",
       "\n",
       "#### The Role of Induction Bias\n",
       "\n",
       "1. **Learning Algorithms**:\n",
       "   - Different algorithms possess different biases that shape their learning. For instance, a decision tree has a bias towards piecewise constant functions, while a linear regression model assumes a linear relationship between input features and the target variable.\n",
       "\n",
       "2. **Generalization**:\n",
       "   - Since no model can memorize all observed training examples, induction bias helps the model make educated guesses about the unknowns. This ability to generalize is crucial: a well-tuned induction bias can lead to good performance on unseen data.\n",
       "\n",
       "3. **Control Overfitting**:\n",
       "   - A model with too little bias can become very flexible, leading to overfitting (where it learns the noise in the training data rather than the actual pattern). Conversely, a model with too much bias might underfit (where it fails to capture the underlying trend in the data).\n",
       "\n",
       "### How Induction Bias Helps in Model Selection\n",
       "\n",
       "1. **Algorithm Comparison**:\n",
       "   - When selecting models, understanding the induction biases of different algorithms allows practitioners to choose the appropriate one based on the nature of the data and the problem at hand.\n",
       "\n",
       "2. **Regularization**:\n",
       "   - Techniques like regularization can be seen as a way to encode bias into the model. By penalizing complexity, one can reduce overfitting. This is important during model selection because it allows for a trade-off between bias and variance.\n",
       "\n",
       "3. **Model Complexity**:\n",
       "   - Induction bias helps in selecting models with appropriate complexity. Simpler models may generalize better when data is scarce, while complex models may be required for rich datasets with intricate patterns.\n",
       "\n",
       "4. **Search Space Reduction**:\n",
       "   - Certain induction biases reduce the effective search space of hypotheses that the model may consider. This efficiency can be crucial in high-dimensional feature spaces where exhaustive searches are computationally impractical.\n",
       "\n",
       "5. **Hyperparameter Optimization**:\n",
       "   - Induction bias often manifests in the hyperparameters of a model (e.g., regularization terms, number of layers in neural networks). Understanding how these hyperparameters influence the bias allows for better fine-tuning of models.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "Induction bias is a foundational concept in machine learning that guides the learning process of algorithms. By understanding and leveraging induction bias, one can make informed decisions in model selection, ultimately leading to better generalization on unseen data. Thus, induction bias plays a critical role in ensuring that the chosen model is neither too complex nor too simplistic for the given problem at hand."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_from_phd_MODEL_GPT ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d793a17c-74f3-4a27-a46d-a844d63a2c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask from a PhD level Super Technician:   explain the following: ask_from_phd_MODEL_GPT ()\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The term `ask_from_phd_MODEL_GPT()` does not directly correspond to a well-known concept, function, or library in standard programming or AI contexts as of my training data cutoff in October 2023. However, I can break it down into its components to provide a speculative explanation. \n",
       "\n",
       "### Breakdown of the Term\n",
       "\n",
       "1. **ask_from_phd**: \n",
       "   - This part of the expression seems to imply a function designed to facilitate inquiries or solicit information from someone with a PhD-level understanding or expertise. \n",
       "   - In a programming context, it might refer to a function or method that triggers a query or request for knowledge.\n",
       "\n",
       "2. **MODEL**:\n",
       "   - This typically refers to a specific framework, structure, or algorithm used in machine learning and artificial intelligence. In the context of natural language processing (NLP), a model can signify the architecture used for language generation or comprehension.\n",
       "   - The `MODEL` could define the type of training data, architecture (like a transformer), or specific configurations that the AI is based upon, potentially including things like size or intended usage.\n",
       "\n",
       "3. **GPT**:\n",
       "   - GPT stands for **Generative Pre-trained Transformer**, which is a type of model developed by OpenAI. \n",
       "   - It is designed for generating human-like text and has undergone extensive training on a diverse array of internet text.\n",
       "   - The \"Generative\" part indicates that the model can produce coherent text based on input prompts, while \"Pre-trained\" signifies it has been initially trained on large datasets and can be fine-tuned on specific tasks.\n",
       "\n",
       "### Hypothetical Function Representation\n",
       "\n",
       "Assuming `ask_from_phd_MODEL_GPT()` represents a function, it may hypothetically indicate a scenario where you interact with a GPT model that is specialized or fine-tuned to simulate conversations with a PhD-level expert in a particular field. This might involve:\n",
       "\n",
       "- **Input Parameters**: Arguments to specify the topic of inquiry, context, or any constraints on the response.\n",
       "- **Output**: A text output that resembles a knowledgeable answer, simulating how an academic expert would respond.\n",
       "\n",
       "### Sample Use Case\n",
       "\n",
       "If this were a real function, a simple pseudocode usage might look like:\n",
       "\n",
       "```python\n",
       "response = ask_from_phd_MODEL_GPT(question=\"What are the implications of quantum computing on cryptography?\")\n",
       "print(response)\n",
       "```\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "While `ask_from_phd_MODEL_GPT()` does not correspond to a known existing function or library, the concept resonates with ongoing developments in the realms of AI, machine learning, and natural language processing. It reflects the capacity to engage AI models in a conversational manner that simulates high-level academic discourse. If this is a specific library or framework you encountered, please provide more context for a more precise answer!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_from_phd_MODEL_GPT ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb5736d-6906-4376-afdf-1b8d82313bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask from a PhD level Super Technician:   Explain, decision tree example in followings in detail:Different algorithms possess different biases that shape their learning. For instance, a decision tree has a bias towards piecewise constant functions,\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Understanding Decision Trees and Their Biases\n",
       "\n",
       "### Overview of Decision Trees\n",
       "\n",
       "A **Decision Tree** is a supervised machine learning algorithm used for both classification and regression tasks. It works by splitting a dataset into subsets based on the value of input features. The result is a tree-like model that aids in decision-making by visualizing the possible outcomes of different decisions. Each internal node of the tree represents a decision based on a feature, each branch represents the outcome of a decision, and each leaf node represents a final decision or prediction.\n",
       "\n",
       "### Bias in Algorithms\n",
       "\n",
       "In machine learning, **bias** refers to the assumptions made by the model to make predictions. Different algorithms have different biases based on their structure and learning process. The stiffness of these assumptions can significantly influence the model's performance on different datasets.\n",
       "\n",
       "### Bias towards Piecewise Constant Functions\n",
       "\n",
       "Decision trees are particularly biased toward approximating **piecewise constant functions**. This means that the model tends to represent functions that are constant within certain regions of the input space, separated by boundaries where the function value can change abruptly. Here’s why this is the case:\n",
       "\n",
       "1. **Splitting Criteria**:\n",
       "    - Decision trees use criteria like **Gini impurity** or **entropy** to determine how to split the data at each node. These criteria aim to create \"pure\" branches, where the target variable is homogeneous. In essence, this leads to regions in the feature space where the predicted output remains constant for a range of input values—hence the term \"piecewise constant.\"\n",
       "\n",
       "2. **Hierarchical Structure**:\n",
       "    - The hierarchical structure of decision trees, where decisions are made sequentially based on features, naturally leads to the formation of distinct regions. For example, consider a scenario with two features leading to a binary classification. The tree will create a series of splits that carve out distinct regions, predicting one class in some areas and another in others.\n",
       "\n",
       "3. **Lack of Smoothness**:\n",
       "    - Unlike linear regression or neural networks that can model smooth transitions, decision trees can only make abrupt changes in predictions. If your true relationship is continuous but has varying segments, decision trees will struggle to fit naturally and will instead create sharp boundaries, resulting in a piecewise constant approximation.\n",
       "\n",
       "### Example of Decision Tree Bias\n",
       "\n",
       "Let’s go through a simple example to illustrate this behavior:\n",
       "\n",
       "#### Dataset:\n",
       "\n",
       "Consider a dataset with two features (X1, X2) and a binary target variable (Y):\n",
       "\n",
       "| X1 | X2 | Y  |\n",
       "|----|----|----|\n",
       "| 1  | 1  | 0  |\n",
       "| 1  | 2  | 0  |\n",
       "| 2  | 1  | 1  |\n",
       "| 2  | 2  | 1  |\n",
       "\n",
       "#### Building a Decision Tree:\n",
       "\n",
       "1. **First Split**:\n",
       "   - Let's say we start by splitting on X1.\n",
       "   - If we choose X1 ≤ 1, all observations (1,1) and (1,2) fall into one region (class 0), whereas (2,1) and (2,2) fall into another (class 1).\n",
       "\n",
       "2. **Second Split**:\n",
       "   - We might make an additional split based on X2 for a more refined categorization.\n",
       "   - This results in two constant predictions in the X1 ≤ 1 region (Y=0) and another constant prediction in the X1 > 1 region (Y=1).\n",
       "\n",
       "#### Visualization:\n",
       "\n",
       "A simple graphical representation could be:\n",
       "\n",
       "```\n",
       "        X1 ≤ 1\n",
       "        /    \\\n",
       "       0     X2 ≤ 1\n",
       "            /    \\\n",
       "           1      1\n",
       "```\n",
       "\n",
       "Here, we find that the decision tree has made constant predictions within certain regions of input space. This showcases the decision tree's bias towards piecewise constant functions.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "In summary, decision trees have a structural bias towards approximating piecewise constant functions due to their splitting criteria, hierarchical nature, and lack of smoothness in predictions. While this can be beneficial for clarity and interpretability, it may also lead to oversimplification, especially in cases where underlying relationships require more sophisticated modeling techniques (e.g., smooth transitions between values). \n",
       "\n",
       "By understanding these biases, practitioners can choose the appropriate model for their data and potentially combine decision trees with ensemble methods to mitigate some of their limitations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_from_phd_MODEL_GPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca27ff14-0108-45ba-8d5a-fa23dea12b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask from a PhD level Super Technician:   what is propensity modelling in ML? Explain in details?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Propensity Modelling in Machine Learning\n",
       "\n",
       "### Definition\n",
       "**Propensity modeling** is a statistical approach used in machine learning that estimates the likelihood or \"propensity\" of a certain event occurring, given certain characteristics or variables. This technique is widely used in various domains, including marketing, healthcare, finance, and social sciences.\n",
       "\n",
       "### Purpose\n",
       "The primary goal of propensity modeling is to identify which individuals or entities are most likely to respond to a given action, such as purchasing a product, clicking on an advertisement, or opting into a program. By understanding these probabilities, organizations can tailor their strategies to target the right audience effectively.\n",
       "\n",
       "### Key Concepts\n",
       "\n",
       "1. **Propensity Score**:\n",
       "   - A propensity score is the probability that a unit (e.g., a person) will receive a treatment given their observed characteristics. It is often used in observational studies to reduce selection bias.\n",
       "\n",
       "2. **Treatment Assignment**:\n",
       "   - In experimentation and observational studies, units may receive a treatment or belong to a control group. The treatment can metaphorically refer to any intervention or program aimed at influencing behavior.\n",
       "\n",
       "3. **Binary Outcomes**:\n",
       "   - Typically, propensity models focus on binary outcomes (e.g., will a customer buy a product: yes/no). Logistic regression is frequently used to model these outcomes.\n",
       "\n",
       "4. **Feature Importance**:\n",
       "   - By analyzing which variables (features) most influence the propensity score, practitioners can derive insights that inform marketing strategies, improve customer targeting, and customize user experiences.\n",
       "\n",
       "### Modeling Techniques\n",
       "\n",
       "There are several methods used to create propensity models, among which include:\n",
       "\n",
       "1. **Logistic Regression**:\n",
       "   - This is one of the simplest and most widely used methods for binary propensity modeling. It gives the estimated probability of an event based on input features.\n",
       "\n",
       "2. **Random Forests and Decision Trees**:\n",
       "   - These tree-based methods allow for capturing nonlinear relationships and interactions between features. They can provide better performance than logistic regression in complex datasets.\n",
       "\n",
       "3. **Gradient Boosting Machines (GBM)**:\n",
       "   - These models build multiple decision trees sequentially, with each tree correcting the errors of the previous one, improving predictive accuracy.\n",
       "\n",
       "4. **Neural Networks**:\n",
       "   - With the advent of deep learning, neural networks can capture complex patterns in high-dimensional data, making them suitable for propensity modeling tasks.\n",
       "\n",
       "### Steps in Propensity Modeling\n",
       "\n",
       "1. **Data Collection**:\n",
       "   - Gather data that includes both the treatment status (i.e., whether the event of interest occurred) and a broad set of features (demographics, behaviors, etc.).\n",
       "\n",
       "2. **Feature Selection**:\n",
       "   - Choose relevant features that might influence the outcome. Feature engineering may also be necessary to enhance model performance.\n",
       "\n",
       "3. **Model Training**:\n",
       "   - Using selected machine learning techniques, train the propensity model on the collected data.\n",
       "\n",
       "4. **Evaluation**:\n",
       "   - Assess the model's performance using metrics such as accuracy, precision, recall, or the area under the receiver operating characteristic curve (AUC-ROC).\n",
       "\n",
       "5. **Application**:\n",
       "   - Utilize the model to predict propensity scores for new or existing customers, allowing organizations to prioritize their efforts based on the predicted likelihood of target behavior.\n",
       "\n",
       "### Challenges in Propensity Modeling\n",
       "\n",
       "1. **Selection Bias**:\n",
       "   - If the sample is biased towards a certain group, the model's estimates may not generalize well to the whole population.\n",
       "\n",
       "2. **Model Overfitting**:\n",
       "   - If the model is too complex, it may perform well on training data but poorly on unseen data. Regularization techniques can help mitigate this.\n",
       "\n",
       "3. **Interpretability**:\n",
       "   - While some models are inherently interpretable (like logistic regression), others (like neural networks) may act as \"black boxes,\" making it difficult to understand the rationale behind predictions.\n",
       "\n",
       "### Applications\n",
       "\n",
       "- **Marketing**: Identifying potential customers likely to respond to campaigns, optimizing marketing spend.\n",
       "- **Healthcare**: Predicting patients’ likelihood to follow treatment plans or respond to specific therapies.\n",
       "- **Finance**: Estimating credit risk or propensity to default on loans.\n",
       "- **Social Sciences**: Understanding behaviors under different societal conditions.\n",
       "\n",
       "### Conclusion\n",
       "Propensity modeling is a robust and valuable approach in machine learning that allows organizations to make data-driven decisions by predicting the likelihood of certain outcomes based on historical data. By accurately estimating these probabilities, businesses can optimally allocate resources, tailor customer experiences, and enhance overall performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_from_phd_MODEL_GPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "affd1ea9-b81a-4d9d-8bf3-d74aebdc3657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask from a PhD level Super Technician:   explain the following statement in detail. May be with examples: \"Because a single model can not be found based on a sample training dataset, ML is an ill-posed problem.\" \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! The statement \"Because a single model cannot be found based on a sample training dataset, ML is an ill-posed problem\" reflects some fundamental challenges in the field of machine learning (ML). Let's break down the concepts involved and elaborate on them with examples.\n",
       "\n",
       "### What is an Ill-posed Problem?\n",
       "\n",
       "In the context of mathematics and optimization, a well-posed problem meets three criteria defined by Henri Poincaré:\n",
       "\n",
       "1. **Existence**: A solution exists.\n",
       "2. **Uniqueness**: The solution is unique.\n",
       "3. **Stability**: The solution's behavior changes continuously with the initial conditions.\n",
       "\n",
       "An ill-posed problem, on the other hand, does not satisfy one or more of these criteria. In machine learning, we often encounter ill-posed problems due to the complexities associated with fitting models to data. \n",
       "\n",
       "### Machine Learning and Ill-posed Problems\n",
       "\n",
       "In machine learning, the training process involves finding a model that best fits a given dataset. However, there are several reasons why this process may lead us to an ill-posed situation:\n",
       "\n",
       "1. **Multiple Solutions**: For the same training dataset, there can be multiple models that fit the data equally well, making the problem ill-posed in terms of uniqueness. This is common in models with many parameters.\n",
       "\n",
       "2. **Overfitting**: If a model is too complex, it may fit the training data too closely, capturing noise rather than the underlying pattern. This overfitting leads to a model that does not generalize well to new data, reflecting instability.\n",
       "\n",
       "3. **Underfitting**: Conversely, if the model is too simple, it won't capture the underlying relationship in the data, resulting in inadequate performance.\n",
       "\n",
       "4. **Data Limitations**: The sample dataset may not represent the broader population, leading to a lack of validity. Training a model on such data may produce misleading results, highlighting the existence criterion’s failure.\n",
       "\n",
       "### Examples\n",
       "\n",
       "#### Example 1: Polynomial Regression\n",
       "\n",
       "Let’s say we have a small dataset of points that we suspect has a quadratic trend:\n",
       "\n",
       "| \\(x\\) | \\(y\\) |\n",
       "|-------|-------|\n",
       "| 1     | 1     |\n",
       "| 2     | 4     |\n",
       "| 3     | 9     |\n",
       "\n",
       "We can fit a polynomial regression model of varying degrees to this dataset. A linear model could provide an overly simplistic approach (underfitting), while a higher-degree polynomial (e.g., degree 10) can fit the training data perfectly (overfitting).  \n",
       "\n",
       "- **Multiple Solutions**: There are infinitely many polynomial curves that can pass through all training data points. This lack of uniqueness in the model is characteristic of an ill-posed problem.\n",
       "\n",
       "#### Example 2: Image Classification\n",
       "\n",
       "In image classification, suppose we train a model to classify pictures of cats and dogs. If we only train on a small dataset with a limited amount of data capturing only a few distinct features, our model may focus on irrelevant features like the background (noise) instead of the actual distinguishing features (like fur type, ear shape). Therefore:\n",
       "\n",
       "- **Overfitting**: The model identifies specific patterns in the training data that do not generalize to unseen images. \n",
       "\n",
       "Conversely, if the model is too basic, it may struggle to capture the complex features necessary for accurate classification, resulting in high error rates. \n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The statement highlights the inherent difficulties in machine learning: finding a single, robust model from a limited and potentially unrepresentative sample of data is non-trivial. We encounter ill-posed problems because:\n",
       "\n",
       "- There's often not a singular best solution.\n",
       "- Models can be sensitive to noise and changes in the dataset (unstable).\n",
       "- The quality and quantity of training data heavily influence the outcome.\n",
       "\n",
       "Understanding these characteristics is crucial for developing more robust machine learning practices, including techniques like regularization, cross-validation, and ensemble learning, which aim to mitigate these issues and lead to more appropriate models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_from_phd_MODEL_GPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4585e-cd91-4fc7-8536-c1e7d8371ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
